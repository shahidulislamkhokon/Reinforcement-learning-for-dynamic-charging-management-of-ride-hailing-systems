# Reinforcement-learning-for-dynamic-charging-management-of-ride-hailing-systems
Develop and implement advanced customer-to-vehicle dispatching reinforcement learning models using gurobipy, gym, Pandas, NumPy, and historical data.
Climate change crisis has accelerated the governments and Transport network company towards their fleet electrification to reduce CO2 emission. Charging management would become a major issue for this clean air transition due to long charging time of EVs compared to that of ICV and limited public charging stations. According to a recent TLC Electrification Repot (Taxi & Limousine Commission, 2022), TLC plans to transform their licensed fleet to electric vehicles (EVs) by 2030 to reduce the air pollution impact (around 600k tons of CO2 in 2022). Currently, there are only limited number of fast charging stations available in the high demand service area. Due to high daily mileage of TLC’s vehicles, drivers need to charge their vehicles several times a day and mainly rely on fast chargers to save charging time (Jenn, 2019). How to optimize the utilization of limited fast charging resource under stochastic environment would be a major challenge for this EV transition.
There are several factors that make smart charging management of electric ride-hailing system challenging. First, customer demand might be volatile which affects vehicles’ charging needs over time. Second, public rapid chargers (charging power ≥50kW/hr) are quite limited due to their high investment costs. This might result in EV’s queuing at these charging stations and increase charging station search costs for the drivers. For this issue, charging reservation is available with additional cost (). For example, EVgo, one of the largest charging network company in USA, allows drivers to reserve an EVgo charger at a cost of 3 dollars. However, it is understudied for the benefit of this system to save drivers’ charging operation time. Third, charging cost might vary according to time of day (ToU), when and how much energy to recharge becomes an important online decision problem of drivers/service operator to maximize their profit. However, existing studies mainly focus on static electric vehicle routing problem or assume uncapacitated charging stations environment. There are still few studies comprising the aforementioned research issues. 
In this study, we consider the problem of dynamic smarting charging of electric ride-hailing system and propose an original reinforcement learning approach mapping the charging problem as an online inventory control problem. Our contributions are summarized as follows.

